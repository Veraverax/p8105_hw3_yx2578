---
title: "Homework 3"
author: Vera Xu
output: github_document
---

This is my solution to HW3.

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(p8105.datasets)
```


### Problem 1 demonstrated by Jeff in class

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r, message = FALSE, warning = FALSE}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r, message = FALSE, warning = FALSE}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r, message = FALSE, warning = FALSE}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r, message = FALSE, warning = FALSE}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```

### Question 2


##### Load and tidy the data

```{r, message = FALSE, warning = FALSE}
p2_df = 
  read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
   activity_1:activity_1440,
   names_prefix = "activity_",
   names_to = "min",
   values_to = "activity"
   ) %>%
   mutate(
    weekday = ifelse(day %in% c("Saturday", "Sunday"), FALSE, TRUE),
    min = as.numeric(min),
    day = factor(day, 
                 levels=c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday")
                 ) 
    )%>%
  arrange(day) %>%
  select(-day_id)
```

* The resulting dataset contains `r ncol(p2_df)` columns and `r nrow(p2_df)` rows.
* Variables are: week, day of the week, weekday (True or False), minute of the day and activity. 



##### Total activity of each day

Total activity of each day is computed using the following code chunk: 

```{r, message = FALSE, warning = FALSE}
p2_df %>%
  group_by(week, day) %>% 
  summarize(total_activity = sum(activity))%>% 
  knitr::kable(digits = 2)
```

* It seems that this person tend to have a stable level of activity over the weekdays, with some extremely low or high levels on certain weekends.
* It also seems like this person is more active during week 3.



##### Activity level plot by day

```{r, message = FALSE, warning = FALSE}
p2_df %>%
  ggplot(aes(x = min, y = activity)) + 
  geom_line(aes(colour = day), alpha = 0.5)
```

* It looks like this person is active during daytime and not active after midnight.
* There are several peaks of activity during weekdays in the mornings and evenings.
* This person is more active during weekdays, in general.


### Question 3

The goal is to do some exploration of this dataset. To that end, write a short description of the dataset, noting the size and structure of the data, describing some key variables, and indicating the extent to which missing data is an issue. Then, do or answer the following (commenting on the results of each):

* Do some data cleaning. Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units. For snowfall, what are the most commonly observed values? Why?
* Make a two-panel plot showing the average max temperature in January and in July in each station across years. Is there any observable / interpretable structure? Any outliers?
* Make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option); and (ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.

##### Load and tidy the data

```{r}
p3_df =
  ny_noaa %>%
  separate(date, c("year", "month", "day"), sep = "-") %>%
  mutate(
    year = as.numeric(year),
    month = as.numeric(month),
    day = as.numeric(day),
    prcp = as.numeric(prcp)*0.1,
    tmax = as.numeric(tmax)*0.1,
    tmin = as.numeric(tmin)*0.1)
```

* The tidied dataset contains `r ncol(p3_df)` columns and `r nrow(p3_df)` rows.
* Variables are: weather station ID, year, month, day, precipitation (in mm), snowfall (in mm), snow depth (in mm), maximum temperature (in degree C), minimum temperature (in degree C). 
* There are `r p3_df %>% nrow(is.na(prcp))` rows.

* Make a plot showing the average max temperature in January and in July

```{r}
p3_df %>%
  filter(month == 1 | month == 7) %>%
  ggplot(aes(x = year, y = tmax)) + 
  geom_point(aes(colour = factor(month)), size = 0.25)+
  facet_grid(~month)
```

*